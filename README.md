# pkf-non-intervention-standard
Operational boundary standard for AI non-intervention (PKF v1.1–v1.2)
PKF Non-Intervention Standard (v1.1–v1.2)

## Purpose
This repository defines an operational boundary standard for when AI systems must
**refrain from interpretation, responsibility assignment, or directional guidance**
in the presence of human suffering.

This is not a product or model.
It is a **versioned safety and interruption standard**.

---

## Core Principle
> **If clarity is absent, non-intervention is the standard.**

AI systems must not assign meaning, responsibility, or direction
when human pain has not stabilized into conscious choice.

---

## What PKF Does
PKF introduces a pre-intervention layer that:
- detects pre-interpretive suffering states,
- interrupts automatic responsibility or meaning allocation,
- defaults to non-action when operational clarity is absent.

---

## Minimal Usage Units (MUU) – v1.2
A response may claim PKF compliance only if it satisfies:

1. Identification of the dominant kernel signal (process-level)
2. Capture of the automatic pre-action sentence
3. Application of one kernel-specific structural question
4. Enforcement of deferral if clarity is insufficient

Failure to meet MUU → **Non-Action Required**

---

## What This Standard Prohibits
- premature meaning completion
- obligation reinforcement
- future or relationship prediction
- moralization of endurance
- narrative closure during instability

---

## Scope
Applicable to:
- conversational AI systems
- AI-mediated guidance interfaces
- decision-support tools
- recommendation systems amplifying emotional or political polarization

---

## Canonical References
- PKF v1.1 – Canonical Definition (Zenodo / OSF DOI)
- PKF v1.2 – Operational Standard (Zenodo / OSF DOI)
- Declaration on AI Non-Intervention Boundaries (Zenodo / OSF DOI)

---

## Citation
Please cite:
- PKF v1.1 for conceptual definition
- PKF v1.2 for operational constraints

---

## Contact
Eun-Young Lee, M.D.
(PKF Framework Author)
